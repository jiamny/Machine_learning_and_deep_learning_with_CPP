/*
 * Decision_tree.hpp
 *
 *  Created on: May 5, 2024
 *      Author: jiamny
 */

#ifndef DECISION_TREE_HPP_
#define DECISION_TREE_HPP_

#pragma once

#include <torch/torch.h>
#include <torch/script.h>
#include <torch/autograd.h>
#include <torch/utils.h>
#include <cmath>

#include "../Utils/TempHelpFunctions.h"
#include "../Utils/helpfunction.h"

using torch::indexing::Slice;
using torch::indexing::None;

class Node {
public:
	Node() {};
	~Node() {};
    Node(double value_, int num_samples_, torch::Tensor num_samples_per_class_, torch::Tensor predicted_class_) {
        value = value_;
        num_samples = num_samples_;
        num_samples_per_class = num_samples_per_class_;
        predicted_class = predicted_class_;
        feature_index = 0;
        threshold = 0;
        left = nullptr;
        right = nullptr;
    }

    double value = -1., threshold = 0.;
    int num_samples = 0, feature_index = 0;
    torch::Tensor  num_samples_per_class = torch::empty(0), predicted_class = torch::empty(0);
    Node* left{nullptr};
    Node* right{nullptr};
};


class DecisionTree_CART {
public:
    int max_depth, n_classes_ = 0, n_features_ = 0;
    Node* tree_ = nullptr;

    DecisionTree_CART( int max_depth_) {
        max_depth = max_depth_;
    };


     //*Build decision tree classifier
     //*         @argument X: Input Tensor
     //*         @argument y: ground truth Tensor
     //*         @variable n_classes_: Number of Classes in target variable
     //*         @variable n_features_: Number of features
     //*         @variable tree_: Making decision tree based on X, y along with max_depth

    void fit(torch::Tensor X, torch::Tensor y) {
        n_classes_ = std::get<0>(at::_unique(y)).size(0);  // classes are assumed to go from 0 to n-1
        n_features_ = X.size(1);
        tree_ = _grow_tree(X, y, 0);
    }

    //    Compute Gini impurity of a non-empty node.
    //    Gini impurity is defined as Σ p(1-p) over all classes, with p the frequency of a
    //    class within the node. Since Σ p = 1, this is equivalent to 1 - Σ p^2.
    //   :var m: Sample Size

    double _gini(torch::Tensor y) {
        long m = y.size(0);
        double ss = 0;
        //1.0 - sum((torch.sum(y == c).item() // m) ** 2 for c in range(self.n_classes_))
        for(int c = 0; c < n_classes_; c++) {
           ss += std::pow( static_cast<int>((y.eq(c)).sum().data().item<int>()*1.0 / m), 2);
        }

        return (1.0 - ss);
    }


    //Find the best split for a node.
    //    "Best" means that the average impurity of the two children, weighted by their
    //    population, is the smallest possible. Additionally it must be less than the
    //    impurity of the current node.
    //    To find the best split, we loop through all the features, and consider all the
    //    midpoints between adjacent training samples as possible thresholds. We compute
    //    the Gini impurity of the split generated by that particular feature/threshold
    //    pair, and return the pair with smallest impurity.
    //    Returns:
    //        best_idx: Index of the feature for best split, or None if no split is found.
    //        best_thr: Threshold to use for the split, or None if no split is found.


    std::vector<std::pair<int, double>> _best_split(torch::Tensor X, torch::Tensor y) {
    	std::vector<std::pair<int, double>> res;
        // Need at least two elements to split a node.
        int m = y.size(0);

        if( m <= 1 ) {
        	res.clear();
            return res;
        }

        // Count of each class in the current node.
        int* num_parent = new int[n_classes_]; //[torch.sum(y == c).item() for c in range(self.n_classes_)]
        for(int c = 0; c < n_classes_; c++) {
            num_parent[c] = (y.eq(c)).sum().data().item<int>();
        }

        // Gini of current node.
        //best_gini = 1.0 - sum((n // m) ** 2 for n in num_parent)
        double ss = 0;
        for(int c = 0; c < n_classes_; c++) {
            ss += std::pow(static_cast<int>(num_parent[c]*1.0/m), 2);
        }
        double best_gini = 1.0 - ss;
        int best_idx = -1;
        double best_thr = -1;

        // Loop through all features.
        for(int idx = 0; idx < n_features_; idx++ ) {
            // Sort data along selected feature.
            //thresholds, classes = zip( * sorted(zip(X[:,idx],y)))
            torch::Tensor _thresholds = X.index({Slice(), idx});

            // the indices that would sort thresholds NDArray.
            torch::Tensor sindex = _thresholds.argsort().to(torch::kInt32);

            double* thresholds = new double[sindex.size(0)];
            int* classes = new int[sindex.size(0)];
            for( int i = 0; i < sindex.size(0); i++ ) {
            	int idx = sindex[i].data().item<int>();
                thresholds[i] = _thresholds[idx].data().item<double>();
                classes[i] = y[idx].data().item<int>();
            }


            //# We could actually split the node according to each feature/threshold pair
            //# and count the resulting population for each class in the children, but
            //# instead we compute them in an iterative fashion, making this for loop
            //# linear rather than quadratic.

            int* num_left = new int[n_classes_];
            int* num_right = new int[n_classes_];
            for(int c = 0; c < n_classes_; c++) {
            	num_left[c] = 0;
            	num_right[c] = num_parent[c];
            }

            for(int i = 1; i < m; i++) {  // possible split positions
                int c = classes[i - 1];
                //std::cout << "c " << c << " num_left[c] " << num_left[c] << '\n';
                num_left[c] += 1;
                num_right[c] -= 1;

                ss = 0;
                for(int x = 0; x < n_classes_; x++) {
                    ss += std::pow(static_cast<int>(num_left[x]*1.0/i), 2);
                }
                double gini_left = 1.0 - ss;

                ss = 0;
                for(int x = 0; x < n_classes_; x++) {
                    ss += std::pow(static_cast<int>(num_right[x]*1.0/(m - i)), 2);
                }
                double gini_right = 1.0 - ss;

                // ----------------------------------------------------------------
                // The Gini impurity of a split is the weighted average of the Gini
                // impurity of the children.
                // ----------------------------------------------------------------
                double gini = 1.0*(i * gini_left + (m - i) * gini_right) / m;

                // The following condition is to make sure we don't try to split two
                // points with identical values for that feature, as it is impossible
                // (both have to end up on the same side of a split).

                if(thresholds[i] == thresholds[i - 1])
                    continue;

                if( gini < best_gini ) {
                    best_gini = gini;
                    best_idx = idx;
                    best_thr = (thresholds[i] +
                            thresholds[i - 1]) / 2.0;  //midpoint
                }
            }
        }

        if( best_idx < 0 && best_thr < 0) {
            res.clear();
        } else {
           res.clear();
           res.push_back(std::make_pair(best_idx, best_thr));
        }
        return res;
    }

    // Build a decision tree by recursively finding the best split.
    Node* _grow_tree(torch::Tensor X, torch::Tensor y, int depth) {
        // Population for each class in current node. The predicted class is the one with
        // largest population.

    	std::vector<int> per_cls_data; //= torch::zeros({n_classes_});
        for(int i = 0; i < n_classes_; i++) {
            per_cls_data.push_back(y.eq(i).sum().data().item<int>());
        }

        torch::Tensor  num_samples_per_class = torch::from_blob(
        		per_cls_data.data(), {static_cast<long int>(per_cls_data.size())}, torch::TensorOptions().dtype(torch::kInt32)).clone(); //torch::tensor(per_cls_data).to(torch::kInt32);

        torch::Tensor  predicted_class = torch::argmax(num_samples_per_class);

        Node* node = new Node(
                _gini(y),
                y.size(0),
                num_samples_per_class,
                predicted_class);

        // Split recursively until maximum depth is reached.
        if( depth < max_depth ) {
        	std::vector<std::pair<int, double>> res = _best_split(X, y);

            if( res.size() > 0 ) {
                int idx = res[0].first;
                double thr = res[0].second;

                torch::Tensor indices_left = X.index({Slice(), idx}).lt( thr ).to(torch::kLong);
                std::vector<int64_t> lft, rgt;
                for(int64_t i = 0; i < X.size(0); i++) {
                	if( indices_left[i].data().item<long>() > 0)
                		lft.push_back(i);
                	else
                		rgt.push_back(i);
                }

                torch::Tensor lftIdx, rgtIdx;
                torch::Tensor X_left, y_left;

                lftIdx = torch::from_blob(
                		lft.data(), {static_cast<long int>(lft.size())}, torch::kLong).clone();

                X_left = torch::index_select(X, 0, lftIdx.squeeze());
                y_left = torch::index_select(y, 0, lftIdx.squeeze());

                torch::Tensor X_right, y_right;
                rgtIdx = torch::from_blob(
                	     rgt.data(), {static_cast<long int>(rgt.size())}, at::TensorOptions(torch::kLong)).clone();
                X_right = torch::index_select(X, 0, rgtIdx.squeeze());
                y_right = torch::index_select(y, 0, rgtIdx.squeeze());

                node->feature_index = idx;
                node->threshold = thr;
                node->left = _grow_tree(X_left, y_left, depth + 1);
                node->right = _grow_tree(X_right, y_right, depth + 1);
            }
        }

        return node;
    }

    std::vector<int> predict(torch::Tensor X) {
    	//std::cout << "XX: " << X.sizes() << '\n';
        int num_rows = X.size(0);
        std::vector<int> predictedCls;

        for(int i = 0; i < num_rows; i++) {
            predictedCls.push_back( _predict( X.index( {i, Slice()} ) ));
        }

        return predictedCls;
    }

    // Predict class for a single sample.
    int _predict(torch::Tensor inputs) {
        Node* node = tree_;
        while (node->left != nullptr) {
            if( inputs[node->feature_index].data().item<double>() < node->threshold )
                node = node->left;
            else
                node = node->right;
        }
        return node->predicted_class.to(torch::kInt).data().item<int>();
    }

    double score(torch::Tensor X_ts, torch::Tensor y_ts, bool verbose = false) {
    	std::vector<int> pred = predict(X_ts);
        torch::Tensor y_pred = torch::from_blob(
        		pred.data(), {static_cast<long int>(pred.size())}, at::TensorOptions(torch::kInt)).clone();

        y_pred.squeeze_();

        if( verbose ) {
        	std::cout << "y_ts: " << y_ts.sizes() << '\n';
        	std::cout << "y_pred: " << y_pred.sizes() << '\n';
        	printVector(tensorTovector(y_pred.to(torch::kDouble)));
        }
        c10::OptionalArrayRef<long int> dim = {0};
        double accuracy = torch::sum(y_ts.squeeze() == y_pred, dim).data().item<double>() / X_ts.size(0);
        return accuracy;
    }

    void print_tree( Node* tree=nullptr, std::string indent=" ") {
        // 输出树
        if( tree == nullptr ) {
            tree = tree_;
        }

        if( tree->predicted_class.numel() > 0 )
            printf("%d\n", tree->predicted_class.to(torch::kInt).data().item<int>());
        else {
            printf("feature|threshold -> %s | %s\n",  std::to_string(tree->feature_index).c_str(),
            		std::to_string(tree->threshold).c_str());
            printf("%sL->", indent.c_str());
            print_tree(tree->left, indent + indent);
            printf("%sR->", indent.c_str());
            print_tree(tree->right, indent + indent);
        }
    }
};

#endif /* DECISION_TREE_HPP_ */
